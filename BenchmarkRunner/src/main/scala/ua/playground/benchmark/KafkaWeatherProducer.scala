package ua.playground.benchmark

import ua.playground.benchmark.models.*
import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}
import org.apache.kafka.common.serialization.StringSerializer
import org.apache.avro.generic.{GenericData, GenericRecord}
import org.apache.avro.Schema
import io.confluent.kafka.serializers.KafkaAvroSerializer // FIX: Corrected import path

import scala.io.Source
import java.util.Properties

object KafkaWeatherProducer:

  def main(args: Array[String]): Unit =
    // ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹: throughput (msg/s) Ğ¸ Ñ‚Ğ¸Ğ¿ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° (wind/sunshine)
    val throughput = if args.length > 0 then args(0).toInt else 100
    val datasetType = if args.length > 1 then args(1) else "wind"

    println(s"=== Starting Weather Producer ===")
    println(s"Dataset: $datasetType")
    println(s"Throughput: $throughput msg/s")
    println(s"=" * 40)

    val producer = createProducer()
    val schema = createAvroSchema()

    try
      datasetType.toLowerCase match
        case "wind" => produceWindData(producer, schema, throughput)
        case "sunshine" => produceSunshineData(producer, schema, throughput)
        case _ =>
          println(s"âŒ Unknown dataset type: $datasetType")
          println("Available types: wind, sunshine")
    catch
      case e: Exception =>
        println(s"âŒ Error: ${e.getMessage}")
        e.printStackTrace()
    finally
      println("\nClosing producer...")
      producer.close()
      println("Producer closed.")

  def createProducer(): KafkaProducer[String, GenericRecord] =
    val props = new Properties()
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092")
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, classOf[StringSerializer].getName)
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, classOf[KafkaAvroSerializer].getName)
    props.put("schema.registry.url", "http://localhost:8081")
    props.put(ProducerConfig.ACKS_CONFIG, "1")
    props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy")
    props.put(ProducerConfig.LINGER_MS_CONFIG, "10")
    props.put(ProducerConfig.BATCH_SIZE_CONFIG, "16384")

    new KafkaProducer[String, GenericRecord](props)

  def createAvroSchema(): Schema =
    // --- EDITED TO LOAD SCHEMA FROM resources/weather.avsc ---
    val resourceStream = Option(getClass.getClassLoader.getResourceAsStream("weather.avsc"))

    val schemaString = resourceStream match {
      case Some(is) => Source.fromInputStream(is).mkString
      case None =>
        // Fallback to inline string if file not found (useful for development),
        // but this is the critical schema that must match the consumer!
        println("âš ï¸ WARNING: weather.avsc not found in resources. Using fallback inline schema.")
        """
            {
              "type": "record",
              "name": "WeatherData",
              "namespace": "ua.playground.benchmark",
              "fields": [
                {"name": "timeObserved", "type": "string"},
                {"name": "stationId", "type": "int"},
                {"name": "stationName", "type": "string"},
                {"name": "metric", "type": "string"},
                {"name": "value", "type": "double"},
                {"name": "producer_ts", "type": "long"}
              ]
            }
            """
    }
    new Schema.Parser().parse(schemaString)
  // --- END EDITED SECTION ---

  def produceWindData(
                       producer: KafkaProducer[String, GenericRecord],
                       schema: Schema,
                       throughput: Int
                     ): Unit =
    val topic = "weather.wind"
    val csvFile = "data/wind_test.csv"

    println(s"\nğŸ“– Reading data from: $csvFile")

    val lines = try {
      Source.fromFile(csvFile).getLines().drop(1).toList // skip header
    } catch {
      case e: Exception =>
        println(s"âŒ Cannot read file: ${e.getMessage}")
        return
    }

    val delayMs = if throughput > 0 then 1000 / throughput else 0

    println(s"ğŸ“Š Total messages to send: ${lines.size}")
    println(s"â±ï¸  Delay between messages: ${delayMs}ms")
    println(s"ğŸ¯ Target throughput: $throughput msg/s")
    println(s"ğŸ“¡ Kafka topic: $topic")
    println(s"\n${"=" * 40}")
    println("Starting to send messages...\n")

    var messageCount = 0
    var successCount = 0
    var errorCount = 0
    val startTime = System.currentTimeMillis()

    for line <- lines do
      val parts = line.split(",").map(_.trim)

      if parts.length >= 4 then
        try
          // CRITICAL: Get producer timestamp (start time of latency)
          val producerTimestamp = System.currentTimeMillis()

          // Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Avro record
          val record = new GenericData.Record(schema)
          record.put("timeObserved", parts(0))
          record.put("stationId", parts(1).toInt)
          record.put("stationName", parts(2))
          record.put("metric", "wind_speed")
          record.put("value", parts(3).toDouble)
          record.put("producer_ts", producerTimestamp) // CRITICAL: Add timestamp

          // Key Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€Ñ‚Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ stationId
          //val key = parts(1)
          val key = s"${parts(1)}-${lines.indexOf(line)}"
          
          val producerRecord = new ProducerRecord[String, GenericRecord](topic, key, record)

          // ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ñ callback
          producer.send(producerRecord, (metadata, exception) => {
            if exception != null then
              errorCount += 1
              println(s"âŒ Error sending message: ${exception.getMessage}")
            else
              successCount += 1
              messageCount += 1

              if messageCount % 10 == 0 then
                val elapsed = (System.currentTimeMillis() - startTime) / 1000.0
                val actualThroughput = if elapsed > 0 then messageCount / elapsed else 0
                print(s"\rğŸ“¤ Sent: $messageCount msgs | âœ… Success: $successCount | " +
                  s"âŒ Errors: $errorCount | ğŸ“Š Rate: ${actualThroughput.formatted("%.1f")} msg/s")
          })

          // ĞšĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ throughput
          if delayMs > 0 then
            Thread.sleep(delayMs)

        catch
          case e: Exception =>
            errorCount += 1
            println(s"\nâŒ Error processing line: ${e.getMessage}")

    // Ğ–Ğ´ĞµĞ¼ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ğ²ÑĞµÑ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
    producer.flush()

    val endTime = System.currentTimeMillis()
    val durationSec = (endTime - startTime) / 1000.0
    val actualThroughput = if durationSec > 0 then successCount / durationSec else 0

    println(s"\n\n${"=" * 40}")
    println("âœ… PRODUCTION COMPLETED")
    println(s"=" * 40)
    println(f"ğŸ“Š Messages sent: $successCount")
    println(f"âŒ Errors: $errorCount")
    println(f"â±ï¸  Duration: ${durationSec}%.2f seconds")
    println(f"ğŸ“ˆ Actual throughput: ${actualThroughput}%.2f msg/s")
    println(f"ğŸ¯ Target throughput: $throughput msg/s")
    println(f"ğŸ“‰ Efficiency: ${(actualThroughput / throughput * 100)}%.1f%%")
    println(s"=" * 40)

  def produceSunshineData(
                           producer: KafkaProducer[String, GenericRecord],
                           schema: Schema,
                           throughput: Int
                         ): Unit =
    val topic = "weather.sunshine"
    val csvFile = "data/sunshine_test.csv"

    println(s"\nğŸ“– Reading data from: $csvFile")

    val lines = try {
      Source.fromFile(csvFile).getLines().drop(1).toList
    } catch {
      case e: Exception =>
        println(s"âŒ Cannot read file: ${e.getMessage}")
        return
    }

    val delayMs = if throughput > 0 then 1000 / throughput else 0

    println(s"ğŸ“Š Total messages to send: ${lines.size}")
    println(s"â±ï¸  Delay between messages: ${delayMs}ms")
    println(s"ğŸ¯ Target throughput: $throughput msg/s")
    println(s"ğŸ“¡ Kafka topic: $topic")
    println(s"\n${"=" * 40}")
    println("Starting to send messages...\n")

    var messageCount = 0
    var successCount = 0
    var errorCount = 0
    val startTime = System.currentTimeMillis()

    for line <- lines do
      val parts = line.split(",").map(_.trim)

      if parts.length >= 4 then
        try
          // CRITICAL: Get producer timestamp (start time of latency)
          val producerTimestamp = System.currentTimeMillis()

          val record = new GenericData.Record(schema)
          record.put("timeObserved", parts(0))
          record.put("stationId", parts(1).toInt)
          record.put("stationName", parts(2))
          record.put("metric", "sunshine")
          record.put("value", parts(3).toDouble)
          record.put("producer_ts", producerTimestamp) // CRITICAL: Add timestamp

          //val key = parts(1)
          val key = s"${parts(1)}-${lines.indexOf(line)}"
          val producerRecord = new ProducerRecord[String, GenericRecord](topic, key, record)

          producer.send(producerRecord, (metadata, exception) => {
            if exception != null then
              errorCount += 1
              println(s"âŒ Error sending message: ${exception.getMessage}")
            else
              successCount += 1
              messageCount += 1

              if messageCount % 10 == 0 then
                val elapsed = (System.currentTimeMillis() - startTime) / 1000.0
                val actualThroughput = if elapsed > 0 then messageCount / elapsed else 0
                print(s"\rğŸ“¤ Sent: $messageCount msgs | âœ… Success: $successCount | " +
                  s"âŒ Errors: $errorCount | ğŸ“Š Rate: ${actualThroughput.formatted("%.1f")} msg/s")
          })

          if delayMs > 0 then
            Thread.sleep(delayMs)

        catch
          case e: Exception =>
            errorCount += 1
            println(s"\nâŒ Error processing line: ${e.getMessage}")

    producer.flush()

    val endTime = System.currentTimeMillis()
    val durationSec = (endTime - startTime) / 1000.0
    val actualThroughput = if durationSec > 0 then successCount / durationSec else 0

    println(s"\n\n${"=" * 40}")
    println("âœ… PRODUCTION COMPLETED")
    println(s"=" * 40)
    println(f"ğŸ“Š Messages sent: $successCount")
    println(f"âŒ Errors: $errorCount")
    println(f"â±ï¸  Duration: ${durationSec}%.2f seconds")
    println(f"ğŸ“ˆ Actual throughput: ${actualThroughput}%.2f msg/s")
    println(f"ğŸ¯ Target throughput: $throughput msg/s")
    println(f"ğŸ“‰ Efficiency: ${(actualThroughput / throughput * 100)}%.1f%%")
    println(s"=" * 40)
